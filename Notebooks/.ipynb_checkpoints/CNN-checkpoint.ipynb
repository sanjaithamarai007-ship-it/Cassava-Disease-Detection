{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c79bc6-5b07-44d9-8bc8-7e2a3f059a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SANJAI\\anaconda3\\envs\\Review\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image as tf_image\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4633a9dc-1046-4b58-a4c6-e28702995d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 1: Configuration & Environment Setup\n",
    "# ==============================================================================\n",
    "\n",
    "# Define the path to your dataset folder.\n",
    "# The folder should contain subfolders for each class (e.g., 'Cassava___healthy').\n",
    "DATA_DIR = './dataset'\n",
    "\n",
    "# Define image dimensions and batch size.\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Path for a user-provided image to classify.\n",
    "# This variable will be updated later with user input.\n",
    "user_image_path = ''\n",
    "\n",
    "# Check if the dataset directory exists.\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(f\"Error: Dataset directory '{DATA_DIR}' not found.\")\n",
    "    print(\"Please make sure you have the 'dataset' folder with the subfolders \"\n",
    "          \"('Cassava___bacterial_blight', etc.) in the same directory as this script.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74264981-02f3-44f0-ac6b-78414bab1c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and pre-processing data...\n",
      "Found 17120 images belonging to 5 classes.\n",
      "Found 4277 images belonging to 5 classes.\n",
      "Found 5 classes: ['Cassava___bacterial_blight', 'Cassava___brown_streak_disease', 'Cassava___green_mottle', 'Cassava___healthy', 'Cassava___mosaic_disease']\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Step 2: Data Loading and Pre-processing\n",
    "# ==============================================================================\n",
    "print(\"Loading and pre-processing data...\")\n",
    "\n",
    "# Use ImageDataGenerator for data augmentation and pre-processing.\n",
    "# Rescale pixel values from [0, 255] to [0, 1].\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,  # Use 20% of data for validation\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load training data.\n",
    "train_ds = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Load validation data.\n",
    "val_ds = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Get the class names from the dataset.\n",
    "class_names = list(train_ds.class_indices.keys())\n",
    "print(f\"Found {len(class_names)} classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f5f33f-35ac-4426-b6b5-13af6907b91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the CNN model...\n",
      "WARNING:tensorflow:From C:\\Users\\SANJAI\\anaconda3\\envs\\Review\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SANJAI\\anaconda3\\envs\\Review\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SANJAI\\anaconda3\\envs\\Review\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               9437696   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9681093 (36.93 MB)\n",
      "Trainable params: 9681093 (36.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Step 3: Build the CNN Model\n",
    "# ==============================================================================\n",
    "print(\"Building the CNN model...\")\n",
    "\n",
    "model = models.Sequential([\n",
    "    # Input layer and first convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # Second convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # Third convolutional block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # Fourth convolutional block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Flatten the 3D output to 1D for the dense layers.\n",
    "    layers.Flatten(),\n",
    "    # Fully connected layers\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5), # Add dropout to prevent overfitting\n",
    "    layers.Dense(len(class_names), activation='softmax') # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model with an optimizer, loss function, and metrics.\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431bc41e-ef97-4382-9221-9733ab64a6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/30\n",
      " 61/535 [==>...........................] - ETA: 10:00 - loss: 1.2206 - accuracy: 0.6158"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Step 4: Train the Model\n",
    "# ==============================================================================\n",
    "print(\"Training the model...\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=30,  # You can adjust the number of epochs\n",
    "    validation_data=val_ds\n",
    ")\n",
    "\n",
    "# Plot training history for visualization\n",
    "def plot_training_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdfea409-4819-45ff-945f-1dc342bfda8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the validation set...\n",
      "1/1 [==============================] - 1s 637ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "\n",
      "Model Accuracy: 0.7692\n",
      "Model F1 Score: 0.7603\n",
      "\n",
      "Classification Report:\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "    Cassava___bacterial_blight       0.44      0.37      0.40       217\n",
      "Cassava___brown_streak_disease       0.78      0.47      0.59       437\n",
      "        Cassava___green_mottle       0.60      0.48      0.53       477\n",
      "             Cassava___healthy       0.48      0.56      0.52       515\n",
      "      Cassava___mosaic_disease       0.87      0.95      0.91      2631\n",
      "\n",
      "                      accuracy                           0.77      4277\n",
      "                     macro avg       0.63      0.57      0.59      4277\n",
      "                  weighted avg       0.76      0.77      0.76      4277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Step 5: Evaluate the Model (Accuracy, F1 Score)\n",
    "# ==============================================================================\n",
    "print(\"\\nEvaluating the model on the validation set...\")\n",
    "\n",
    "# Get predictions and true labels from the validation set\n",
    "val_labels = []\n",
    "val_predictions = []\n",
    "for i in range(len(val_ds)):\n",
    "    batch = val_ds.next()\n",
    "    labels = np.argmax(batch[1], axis=1)\n",
    "    preds = np.argmax(model.predict(batch[0]), axis=1)\n",
    "    val_labels.extend(labels)\n",
    "    val_predictions.extend(preds)\n",
    "\n",
    "# Convert to numpy arrays for calculation\n",
    "val_labels = np.array(val_labels)\n",
    "val_predictions = np.array(val_predictions)\n",
    "\n",
    "# Calculate and print metrics.\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "f1 = f1_score(val_labels, val_predictions, average='weighted')\n",
    "report = classification_report(val_labels, val_predictions, target_names=class_names)\n",
    "\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Model F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "899b5670-f0de-4528-9c13-61d012b60986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------\n",
      "Enter the path to a cassava leaf image to get its prediction.\n",
      "Example: 'data/test_image.jpg'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Image Path:  C:\\Users\\SLM_INFOTECH\\Documents\\Anaconda\\Tapioca\\dataset\\Cassava___mosaic_disease\\30215524.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "\n",
      "Prediction Results:\n",
      "The model predicts the leaf image has: Cassava___mosaic_disease\n",
      "Confidence: 1.00\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Step 6: Prediction on a New Image\n",
    "# ==============================================================================\n",
    "\n",
    "def predict_new_image(image_path):\n",
    "    \"\"\"\n",
    "    Loads and pre-processes a single image for prediction.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The file path to the image.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Predicted class name and confidence score.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: The image file '{image_path}' does not exist.\")\n",
    "        return None, None\n",
    "\n",
    "    # Load the image and resize it to the target size.\n",
    "    img = tf_image.load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    # Convert the image to a numpy array.\n",
    "    img_array = tf_image.img_to_array(img)\n",
    "    # Expand dimensions to create a batch of size 1.\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    # Rescale pixel values from [0, 255] to [0, 1].\n",
    "    img_array /= 255.0\n",
    "\n",
    "    # Make the prediction.\n",
    "    predictions = model.predict(img_array)\n",
    "    # Get the index of the class with the highest probability.\n",
    "    predicted_class_index = np.argmax(predictions[0])\n",
    "    # Get the confidence score (probability).\n",
    "    confidence = np.max(predictions[0])\n",
    "\n",
    "    # Get the predicted class name from the class_names list.\n",
    "    predicted_class_name = class_names[predicted_class_index]\n",
    "\n",
    "    return predicted_class_name, confidence\n",
    "\n",
    "# Example Usage:\n",
    "print(\"\\n-------------------------------------------------------------\")\n",
    "print(\"Enter the path to a cassava leaf image to get its prediction.\")\n",
    "print(\"Example: 'data/test_image.jpg'\")\n",
    "#user_image_path = C:\\\\Users\\\\SLM_INFOTECH\\\\Documents\\\\Anaconda\\\\Tapioca\\\\dataset\\\\Cassava___green_mottle\\\\22116035.jpg\n",
    "user_image_path = input(\"Image Path: \")\n",
    "predicted_class, confidence_score = predict_new_image(user_image_path)\n",
    "\n",
    "if predicted_class:\n",
    "    print(\"\\nPrediction Results:\")\n",
    "    print(f\"The model predicts the leaf image has: {predicted_class}\")\n",
    "    print(f\"Confidence: {confidence_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02c342-ee64-47c1-89cf-4ee78c1997f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
