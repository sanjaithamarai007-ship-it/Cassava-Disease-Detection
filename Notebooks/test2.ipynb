{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25530d5f-99d0-4d3c-be6e-2a35db326439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image as tf_image\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8bb6bbd-eaae-4a8c-bb25-7ef9c6caee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Step 1: Configuration & Environment Setup\n",
    "# ==============================================================================\n",
    "\n",
    "# Define the path to your dataset folder.\n",
    "# The folder should contain subfolders for each class (e.g., 'Cassava___healthy').\n",
    "DATA_DIR = './dataset'\n",
    "\n",
    "# Define image dimensions and batch size.\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Path for a user-provided image to classify.\n",
    "# This variable will be updated later with user input.\n",
    "user_image_path = ''\n",
    "\n",
    "# Check if the dataset directory exists.\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(f\"Error: Dataset directory '{DATA_DIR}' not found.\")\n",
    "    print(\"Please make sure you have the 'dataset' folder with the subfolders \"\n",
    "          \"('Cassava___bacterial_blight', etc.) in the same directory as this script.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0202188b-5995-4e92-abb0-9f5b325ceca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and pre-processing data...\n",
      "Found 17120 images belonging to 5 classes.\n",
      "Found 4277 images belonging to 5 classes.\n",
      "Found 5 classes: ['Cassava___bacterial_blight', 'Cassava___brown_streak_disease', 'Cassava___green_mottle', 'Cassava___healthy', 'Cassava___mosaic_disease']\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Step 2: Data Loading and Pre-processing\n",
    "# ==============================================================================\n",
    "print(\"Loading and pre-processing data...\")\n",
    "\n",
    "# Use ImageDataGenerator for data augmentation and pre-processing.\n",
    "# Rescale pixel values from [0, 255] to [0, 1].\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,  # Use 20% of data for validation\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load training data.\n",
    "train_ds = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Load validation data.\n",
    "val_ds = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Get the class names from the dataset.\n",
    "class_names = list(train_ds.class_indices.keys())\n",
    "print(f\"Found {len(class_names)} classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "424dc10e-3de4-4a40-b12e-b7348d0babf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the CNN model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 111, 111, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 12, 12, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               9437696   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9681093 (36.93 MB)\n",
      "Trainable params: 9681093 (36.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Step 3: Build the CNN Model\n",
    "# ==============================================================================\n",
    "print(\"Building the CNN model...\")\n",
    "\n",
    "model = models.Sequential([\n",
    "    # Input layer and first convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # Second convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # Third convolutional block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    # Fourth convolutional block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Flatten the 3D output to 1D for the dense layers.\n",
    "    layers.Flatten(),\n",
    "    # Fully connected layers\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5), # Add dropout to prevent overfitting\n",
    "    layers.Dense(len(class_names), activation='softmax') # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model with an optimizer, loss function, and metrics.\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f1edfd-4630-4e80-bfe1-6bc9432e99b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cde8d7-1d27-47ce-98b6-51786f0cf076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
